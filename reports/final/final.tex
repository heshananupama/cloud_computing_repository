\documentclass[11pt]{article}

\def\baselinestretch{1}
\usepackage{times}
\usepackage{titlesec}
\usepackage{fancyhdr} 
\usepackage{pagecounting}
\usepackage{color}
\usepackage[yyyymmdd,hhmmss]{datetime}
\usepackage{hyperref}
\usepackage{lastpage}
\usepackage{lipsum}

\newcommand\bb[1]{\mbox{\em #1}}
\newcommand{\eat}[1]{}
\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}

\titleformat{\section}{\vspace{- 0.5 \baselineskip}\normalfont\fontsize{12}{12}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\vspace{- 0.5 \baselineskip}\normalfont\fontsize{11}{11}\bfseries}{\thesubsection}{1em}{}

\begin{document}

\renewcommand{\headrulewidth}{0pt} 
\renewcommand{\footrulewidth}{0pt} 
\pagestyle{fancy}
\cfoot{}
\lhead{}
\rhead{}
\rfoot{\itshape\textcolor{gray}{Page \thepage\ of \pageref{LastPage}}}
\lfoot{\itshape\textcolor{gray}{CS525T Cloud Computing Final Report}}

\begin{center}
{\LARGE \bf Project Final Report: Comparison Between Virtual Machines and Containers for Cloud End Users} \\
{\normalsize \emph{Heshan Perera, Michael Ludwig}}\\
\end{center}

% 1. The final report should be about 10-12 pages long using the same Latex template for paper review.
% 2. It is okay to reuse texts from your proposal, but the final report should focus on the following questions. One way to think about the final report is to use the proposal as a roadmap and fill in with information including what you chose to do, and why you chose to do so.
%     a. A concrete description of the problem statement: what were the exact research questions you work on?
%     b. A more comprehensive related work: this is what makes
%     c. A detailed description of the proposed ideas, and techniques that were used to implement them. You should focus on explaining the ideas and rationales, instead of only describing what you have done. It is not necessary to copy and paste the project code as the entire project code should be submitted together and I will have access to them.
%     d. The evaluation section can be structured as 1) experiment setup, 2) experiment results, e.g., tables or figures, 3) result analysis that explains the significance of results, for each question you are evaluating.
%     e. The conclusion section which should provide readers the key takeaways and describe any other solutions that were attempted and potential solutions.
%     f. The division of work done by each team member.


\section{Problem Statement}

NOTES:
- include startup/shutdown times for VMs/containers
- include image sizes for VMs/containers

Modern cloud computing offers a vast array of options when deciding how to run an application. The traditional approach to this is to use VMs. This requires installing the application on an OS and exporting the entire disk image. When it comes time to run the application, or scale an existing setup, a new VM would be booted from this image. This is perfectly acceptable for services with a consistent workload, but for services such as web applications, databases, or anything where users come and go, or jobs run on a periodic schedule, the workload will likely fluctuate. This means it's important to scale the infrastructure up and down to get the best utilization, decreasing cost for the cloud user, and increasing effective capacity for the cloud provider. To do this, the isolation mechanism needs to be able to start up quickly. Additionally, it needs to have little overhead, so the hardware can be used to its full capacity.

This report aims to identify specific differences and similarities between VMs and containers when using them as an end user on a cloud service, specifically AWS. To start off, it's important to know the basics of each, such as unit cost per hardware resource and startup times. However, the main subject of interest is performance under various workloads. How these technologies fair under common workload scenarios it an important deciding factor when choosing infrastructure. In addition to this, it also helps to pinpoint the cause of performance differences. This may help mitigate these problems for users who don't have much of a choice. Lastly, other factors besides cost and performance may be important for some users, such as level of isolation, so this is also investigated.


\section{Related Work}

Other work exists that compares VMs with containers. "Containers and Virtual Machines at Scale: A Comparative Study" by Chaufournier et al compares VMs and containers on bare metal using five different workloads. They concluded that containers running with LXC have similar performance in most areas except disk I/O, but VMs provide better isolation. "An Updated Performance Comparison of Virtual Machines and Linux Containers" by Felter et al confirms the finding that containers have only a small performance cost versus bare metal. This paper used Docker instead of LXC, which closer aligns to our work due to the packaging format and runtime. Similarly, our work ran benchmarks on VMs and containers, though it was not necessarily on bare-metal. Instead, we used cloud services as presented to customers to compare the two, factoring in cost and scalability. This body of work shows that the two technologies are expected to have similar raw performance in terms of individual resources such as CPU, memory, disk, and network.

One paper that had very similar goals and methods as ours was "Performance Comparison between Container-based and VM-based Services" by Salah et al. They compared the throughput, latency, and CPU utilization of an Apache web service running on EC2 and ECS, and concluded that EC2 has significantly higher performance. However, there are some important differences with our work. Their paper was published in 2017, and used self-managed instances for ECS. We used ECS with Fargate 1.4 which uses containerd on top of EC2, with the new Fargate control-plane that uses Firecracker micro VMs, leading to better security and likely a different performance profile. Additionally, they did not investigate causes for the disparity, such as benchmarking specific resources.

"Container and Microservice Driven Design for Cloud Infrastructure DevOps" by Kang et al does a comparison of VM and container approaches for DevOps. The key takeaway here is the ability of each to scale. They measure the time and resources it takes to deploy and scale parts of an OpenStack control plane. It takes the VM much longer to start up, and slightly longer to instantiate the service, taking 1.5 times longer in total than the container, along with higher CPU usage. They use KVM as the hypervisor and Docker for managing containers.

Other work illustrates the benefits of containers besides scalability and performance, namely easier management of the cluster. "Systems Modeling: Methodologies and Tools" explains the advantages of a container orchestration, including scheduling, fault tolerance, load balancing, configuration management, and service discovery. Although some of these features can be found for VMs, due to the history of microservices, the systems are more accessible for end-users with containers. Kubernetes, Docker Swarm, and others allow automatic management of a production ready system after defining a handful of configurations. The point here is that, in many cases, using containers would be ideal if not outweighted by any possible performance (or security) disadvantages. This report will shed light on that, and can be used to help cloud users determine which technology is right for them.

In terms of security, containers are often considered less secure, in large part due to kernel sharing. "A Measurement Study on Linux Container Security: Attacks and
Countermeasures" by Lin et al confirms this by running 223 exploits on containers and finding that 11 of them break container isolation. They find that the container runtime doesn't provide enough security, as over 50\% of 88 exploits they tested in-depth ran on both the host and inside the container. "Firecracker: Lightweight Virtualization
for Serverless Applications" by Agache et al aims to fix this. Firecracker uses micro VMs to achieve half the boot time of leading hypervisors and maintain the same level of isolation. It does this by cutting down on unnecesary kernel components and providing a minimal manager process. Although technically this is VM technology, it has the same goals as containers and is compatible with the Docker ecosystem. Our experiments use Firecracker as part of the latest version of AWS Fargate.


\section{Key Ideas}


\section{Evaluation}


\section{Conclusion}


\section{Division of Work}



https://aws.amazon.com/blogs/containers/under-the-hood-fargate-data-plane/

\end{document}
